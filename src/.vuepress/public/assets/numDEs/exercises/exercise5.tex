
% This LaTeX was auto-generated from MATLAB code.
% To make changes, update the MATLAB code and republish this document.

\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}
\usepackage{mathrsfs}
\usepackage{bm}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\graphicspath{ {./images/} }
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{makecell}  % 表格换行


\usepackage{hyperref}
\hypersetup{
    colorlinks=true,     % 启用颜色链接
    linkcolor=blue,     % 内部链接的颜色
    citecolor=blue,      % 引用文献的颜色
    urlcolor=blue,       % URL链接的颜色
    linktoc=red,      % 不影响目录链接颜色
}

\usepackage[a4paper, top=1in, bottom=1in, left=1in, right=1in]{geometry}

\title{
{\bf \huge Notes on M\"untz-Jackson Theorem}
%{\bf \large For M\"untz systems on [0,1]}
}
\author{Huaijin Wang}
\date{December 10, 2024}


\begin{document}


\newtheorem{definition}{Definition}[section]
\newtheorem{property}{Property}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[]
\newtheorem{notation}{Notation Declaration}[]
\newtheorem{question}{Question}[]
\newtheorem{exercise}{Exercise}[section]

%\maketitle




\newpage



\setcounter{section}{2}
\setcounter{exercise}{14}
\begin{exercise}
Consider the elliptic problem
\[
\begin{aligned}
-u&_{xx}  =f, \quad \forall x\in (a,b),\\
& u(a) = 0, \ u^\prime(b) = \beta,
\end{aligned}
\]
and its finite difference schema
\[
\begin{aligned}
 - \frac{u_{i+1} - 2u_i + u_{i-1}}{h^2} = f_i,& \quad \forall i=1,\cdots,N-1,\\
 u_0 = 0,& \\
 \frac{u_{N}- u_{N-1}}{h} = \beta, & \\
\end{aligned}
\]
in an uniform mesh $\{x_i\}_{i=0}^{N}$, $x_i = a+ih$, $h = (b-a)/N$. \\
1) Derive an estimate for the truncation errors:
\[
R_i^{(1)} = L_h [u(x_i)] - [L u] (x_i) \text{  for  } i=1,\cdots,N-1, \ R^{(2)} = \frac{u(x_{N}) - u(x_{N-1})}{h} - u^\prime(x_{N}).
\]
2) Rewrite the discrete problem under matrix form. \\
3) Establish an a priori estimate for $\|u_h\|_1$. \\
4) Derive an error estimate for $\|e_h\|_1$, where $e_i = u(x_i) - u_i$.
\end{exercise}
\begin{proof}[Solution]
1). Let the operator $L u = -u_{xx}$ and the discrete operator $L_h$ on $\{u_i\}_{i=1}^{N-1}$ as
\[
L_h u_i =  - \frac{u_{i+1} - 2u_i + u_{i-1}}{h^2}.
\]
By the Tylor development:
\[
u(x_{i+1}) = u(x_i) + h u^\prime(x_i) + \frac{h^2}{2} u^{\prime \prime} (x_i) + \frac{h^3}{3!} u^{(3)} (x_i) + \frac{h^4}{4!} u^{(4)} (\xi_i), \ \text{for some} \ \xi_i \in (x_i, x_{i+1}),
\]
\[
u(x_{i-1}) = u(x_i) - h u^\prime(x_i) + \frac{h^2}{2} u^{\prime \prime} (x_i) - \frac{h^3}{3!} u^{(3)} (x_i) + \frac{h^4}{4!} u^{(4)} (\eta_i), \ \text{for some} \ \eta_i \in (x_{i-1},x_{i}),
\]
we obtain that $R^{(1)}_i =  L_h [u(x_i)] - [L u] (x_i) = O(h^2)$, while $R^{(2)} = O(h)$  as $h\to 0$. \\
2).
\[
\left[\begin{array}{ccccc}
\frac{2}{h^2} & -\frac{1}{h^2} & & & \\
-\frac{1}{h^2} & \frac{2}{h^2} & -\frac{1}{h^2} & & \\
& \ddots & \ddots & \ddots & \\
& & -\frac{1}{h^2} & \frac{2}{h^2} & -\frac{1}{h^2} \\
& & & -\frac{1}{h} & \frac{1}{h}
\end{array}\right]\left[\begin{array}{c}
u_1 \\
u_2 \\
\vdots \\
u_{N-1} \\
u_N
\end{array}\right]=\left[\begin{array}{c}
f_1 \\
f_2 \\
\vdots \\
f_{N-1} \\
\beta
\end{array}\right],
\]
or
\[
\left[\begin{array}{ccccc}
2 & -1 & & & \\
-1 & 2 & -1 & & \\
& \ddots & \ddots & \ddots & \\
& & -1 & 2 & -1 \\
& & & -1 & 1
\end{array}\right]\left[\begin{array}{c}
u_1 \\
u_2 \\
\vdots \\
u_{N-1} \\
u_N
\end{array}\right]=\left[\begin{array}{c}
h^2 f_1 \\
h^2 f_2 \\
\vdots \\
h^2 f_{N-1} \\
h \beta
\end{array}\right].
\]
3). Note that $L_h u_i=-\left(\left(u_i\right)_{\bar{x}}\right)_{\hat{x}}$, then multiplying both sides of the finite difference schema $L_h u_i = f_i$ by $u_i h_i$ yields
\[
-\left(\left(u_i\right)_{\bar{x}}\right)_{\hat{x}} u_i h_i  = f_i u_i h_i,\quad \forall i=1,\cdots,N-1.
\]
Summing in $i$ gives
\[
- \left(\left(\left(u_h\right)_{\bar{x}}\right)_{\hat{x}}, u_h \right )_{I_h} = (f_h, u_h)_{I_h}.
\]
In virtue of discrete Green formula \eqref{eq:d-gf} and the fact that $u_0=0$, we have
\[
- \left(\left(\left(u_h\right)_{\bar{x}}\right)_{\hat{x}}, u_h \right )_{I_h} = \left( (u_h)_{\bar{x}}, (u_h)_{\bar{x}} \right)_{I_h^+} - (u_N)_{\bar{x}} u_N.
\]
Note that $(u_N)_{\bar{x}} = \beta$, and
\[
u_N = \sum_{i=1}^N (u_i)_{\bar{x}} h \leqslant \left(\sum_{i=1}^N h \right)^{1/2} \left(\sum_{i=1}^N (u_i)_{\bar{x}}^2 h \right)^{1/2} = \sqrt{b-a} |u_h|_1.
\]
We have
\[
|u_h|_1^2 = \left( (u_h)_{\bar{x}}, (u_h)_{\bar{x}} \right)_{I_h^+} = \beta u_N + (f_h, u_h)_{I_h}.
\]
By discrete Cauchy-Schwarz inequality:
\[
(f_h, u_h)_{I_h} \leqslant \left( \sum_{i=1}^{N-1} f_i^2 h \right )^{1/2} \left( \sum_{i=1}^{N-1} u_i^2 h\right)^{1/2} \leqslant \|f_h\|_0 \|u_h\|_0.
\]
By discrete Poincar\'e inequality: $\|u_h\|_0 \leqslant C |u_h|_1$, we obtain
\[
|u_h|_1 \leqslant C (\|f_h\|_0 + |\beta|),
\]
where $C$ represents a constant depending only on $a$ and $b$, and it may different in different scenarios. Thus by using discrete Poincar\'e again, we obtain
\[
\|u_h\|_1 = \left( \|u_h\|_0^2 + |u_h|_1^2 \right)^{1/2} \leqslant C |u_h|_1 \leqslant C (\|f_h\|_0 + |\beta|).
\]
4). It is obvious that 
\[
\left\{
\begin{aligned}
& L_h e_i=R_i,  \quad \forall i=1,2, \cdots, N-1, \\
& e_0=0, \\
& \frac{e_N-e_{N-1}}{h}=R^{(2)}.
\end{aligned} \right.
\]
By 1) and 3) we have
\[
\|e_h\|_1 \leqslant C (\|R_h^{(1)}\|_0 + |R^{(2)}|) = O(h)\ \text{as}\ h\to 0.
\]
\end{proof}


\setcounter{section}{3}
\setcounter{exercise}{0}
\begin{exercise}
Derive an estimate for the truncation error of the 9-point schema.
\end{exercise}
\begin{proof}[Solution]
Consider the 2D problem:
\[
\left \{
\begin{aligned}
L u (\mathbf{x}) = f(\mathbf{x}),& \quad \forall \mathbf{x} \in \Omega, \\
u(\mathbf{x}) = 0,&  \quad \forall \mathbf{x} \in \partial \Omega, \\
\end{aligned}
\right .
\]
where $\Omega = (a,b)^2$ and $L u = -\Delta u$. Let $\{\mathbf{x}_{i, j}: i=0,\cdots,N_x, j=0,\cdots,N_y \}$ be the discrete mesh in $\Omega$ equispaced of $h_x = (b-a)/N_x$ and $h_y = (b-a)/N_y$ over $x$ and $y$ axis respectively. Then the coordinate of $\mathbf{x}_{i,j}$ is $(a+i h_x, a+j h_y)$.

The 9-point schema is
\[
\left\{
\begin{aligned}
\bar{L}_h u_{i,j} = \bar{f} (\mathbf{x}_{i,j}), & \quad \forall \mathbf{x}_{i,j} \in \Omega, \\
u_{i,j} = 0,& \quad \forall \mathbf{x}_{i,j} \in \partial \Omega,
\end{aligned}
\right.
\]
where 
\begin{equation}
\begin{aligned}
\bar{L}_h u_{i,j} = L_h u_{i,j} - \frac{h_x^2+h_y^2}{12 h_x^2 h_y^2} & \left[ u_{i+1,j+1} - 2u_{i,j+1} + u_{i-1,j+1} \right.  \\
& - 2u_{i+1,j} + 4u_{i,j} - 2u_{i-1,j}  \\
 & \left.  + u_{i+1,j-1} - 2u_{i,j-1} + u_{i-1,j-1} \right], 
\end{aligned}
\label{eq:3-1-1}
\end{equation}
\begin{equation}
L_h u_{i,j} = -\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h_x^2} - \frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h_y^2},
\label{eq:3-1-2}
\end{equation}
and $\bar{f} (\mathbf{x}_{i,j})$ is given by
\begin{equation}
\bar{f} (\mathbf{x}_{i,j})= f(\mathbf{x}_{i,j}) + \frac{1}{12} \left( h_x^2 \frac{\partial^2 f}{\partial x^2} + h_y^2 \frac{\partial^2 f}{\partial y^2} \right) (\mathbf{x}_{i,j}).
\label{eq:3-1-3}
\end{equation}
The truncation error $\bar{R}_{i,j} = \bar{L}_h [u(\mathbf{x}_{i,j})] - \bar{f}(\mathbf{x}_{i,j})$. By the Tylor development, we have
\[
u(\mathbf{x}_{i+1,j}) = u(\mathbf{x}_{i,j}) + h_x \frac{\partial u}{\partial x} (\mathbf{x}_{i,j}) + \frac{h_x^2}{2} \frac{\partial^2 u}{\partial x^2} (\mathbf{x}_{i,j}) + \frac{h_x^3}{3!} \frac{\partial^3 u}{\partial x^3} (\mathbf{x}_{i,j}) 
+ \frac{h_x^4}{4!} \frac{\partial^4 u}{\partial x^4} (\mathbf{x}_{i, j}) + O(h_x^4),  
\]
\[
u(\mathbf{x}_{i-1,j}) = u(\mathbf{x}_{i,j}) - h_x \frac{\partial u}{\partial x} (\mathbf{x}_{i,j}) + \frac{h_x^2}{2} \frac{\partial^2 u}{\partial x^2} (\mathbf{x}_{i,j}) - \frac{h_x^3}{3!} \frac{\partial^3 u}{\partial x^3} (\mathbf{x}_{i,j}) 
+ \frac{h_x^4}{4!} \frac{\partial^4 u}{\partial x^4} (\mathbf{x}_{i, j}) + O(h_x^4), 
\]
\[
u(\mathbf{x}_{i,j+1}) = u(\mathbf{x}_{i,j}) + h_y \frac{\partial u}{\partial y} (\mathbf{x}_{i,j}) + \frac{h_y^2}{2} \frac{\partial^2 u}{\partial y^2} (\mathbf{x}_{i,j}) + \frac{h_y^3}{3!} \frac{\partial^3 u}{\partial y^3} (\mathbf{x}_{i,j})
+ \frac{h_y^4}{4!} \frac{\partial^4 u}{\partial y^4} (\mathbf{x}_{i,j}) + O(h_y^4),
\]
\[
u(\mathbf{x}_{i,j-1}) = u(\mathbf{x}_{i,j}) - h_y \frac{\partial u}{\partial y} (\mathbf{x}_{i,j}) + \frac{h_y^2}{2} \frac{\partial^2 u}{\partial y^2} (\mathbf{x}_{i,j}) - \frac{h_y^3}{3!} \frac{\partial^3 u}{\partial y^3} (\mathbf{x}_{i,j})
+ \frac{h_y^4}{4!} \frac{\partial^4 u}{\partial y^4} (\mathbf{x}_{i,j}) + O(h_y^4).
\]
Replacing $u_{i,j}$ with $u(\mathbf{x}_{i,j})$ in \eqref{eq:3-1-2} and 
inserting those above formulae into it, we obtain 
\begin{equation}
L_h [u(\mathbf{x}_{i,j})] = - \frac{\partial^2 u}{\partial x^2} (\mathbf{x}_{i,j}) - \frac{\partial^2 u}{\partial y^2} (\mathbf{x}_{i,j}) - \frac{1}{12} \left(h_x^2 \frac{\partial^4 u}{\partial x^4} (\mathbf{x}_{i,j}) + h_y^2 \frac{\partial^4 u}{\partial y^4} (\mathbf{x}_{i,j}) \right) + O(h_x^2 + h_y^2).
\label{eq:3-1-4}
\end{equation}
Similarly,
\[
u(\mathbf{x}_{i+1,j+1}) - 2u(\mathbf{x}_{i,j+1}) + u(\mathbf{x}_{i-1,j+1})
= h_x^2 \frac{\partial^2 u}{\partial x^2}(\mathbf{x}_{i,j+1}) + \frac{h_x^4}{12} \frac{\partial^4 u}{\partial x^4}(\mathbf{x}_{i,j+1}) + O(h_x^4),
\]
\[
-2u(\mathbf{x}_{i+1,j}) + 4u(\mathbf{x}_{i,j}) - 2u(\mathbf{x}_{i-1,j}) =
-2h_x^2 \frac{\partial^2 u}{\partial x^2}(\mathbf{x}_{i,j}) - \frac{h_x^4}{6} \frac{\partial^4 u}{\partial x^4}(\mathbf{x}_{i,j}) + O(h_x^4),
\]
\[
u(\mathbf{x}_{i+1,j-1}) - 2u(\mathbf{x}_{i,j-1}) + u(\mathbf{x}_{i-1,j-1})
= h_x^2 \frac{\partial^2 u}{\partial x^2}(\mathbf{x}_{i,j-1}) + \frac{h_x^4}{12} \frac{\partial^4 u}{\partial x^4}(\mathbf{x}_{i,j-1}) + O(h_x^4).
\]
By Tylor development, we have
\[
\frac{\partial^2 u}{\partial x^2} (\mathbf{x}_{i,j+1}) = \frac{\partial^2 u}{\partial x^2} (\mathbf{x}_{i,j}) + h_y \frac{\partial^3 u}{\partial y \partial x^2} (\mathbf{x}_{i,j}) + \frac{h_y^2}{2} \frac{\partial^4 u}{\partial y^2 \partial x^2} (\mathbf{x}_{i,j}) + \frac{h_y^3}{3!} \frac{\partial^5 u}{\partial y^3 \partial x^2} (\mathbf{x}_{i,j}) + \frac{h_y^4}{4!} \frac{\partial^6 u}{\partial y^4 \partial x^2} (\mathbf{x}_{i,j}) +O(h_y^4),
\]
\[
\frac{\partial^2 u}{\partial x^2} (\mathbf{x}_{i,j-1}) = \frac{\partial^2 u}{\partial x^2} (\mathbf{x}_{i,j}) - h_y \frac{\partial^3 u}{\partial y \partial x^2} (\mathbf{x}_{i,j}) + \frac{h_y^2}{2} \frac{\partial^4 u}{\partial y^2 \partial x^2} (\mathbf{x}_{i,j}) - \frac{h_y^3}{3!} \frac{\partial^5 u}{\partial y^3 \partial x^2} (\mathbf{x}_{i,j}) + \frac{h_y^4}{4!} \frac{\partial^6 u}{\partial y^4 \partial x^2} (\mathbf{x}_{i,j}) +O(h_y^4),
\]
\[
\frac{\partial^4 u}{\partial x^4} (\mathbf{x}_{i,j+1}) = \frac{\partial^4 u}{\partial x^4} (\mathbf{x}_{i,j}) +  h_y \frac{\partial^5 u}{\partial y \partial x^4} (\mathbf{x}_{i,j}) + \frac{h_y^2}{2} \frac{\partial^6 u}{\partial y^2 \partial x^4} (\mathbf{x}_{i,j}) + O(h_y^2),
\]
\[
\frac{\partial^4 u}{\partial x^4} (\mathbf{x}_{i,j-1}) = \frac{\partial^4 u}{\partial x^4} (\mathbf{x}_{i,j}) -  h_y \frac{\partial^5 u}{\partial y \partial x^4} (\mathbf{x}_{i,j}) + \frac{h_y^2}{2} \frac{\partial^6 u}{\partial y^2 \partial x^4} (\mathbf{x}_{i,j}) + O(h_y^2).
\]
Then
\begin{equation}
\begin{aligned}
 & u(\mathbf{x}_{i+1,j+1}) - 2u(\mathbf{x}_{i,j+1}) + u(\mathbf{x}_{i-1,j+1})    -2u(\mathbf{x}_{i+1,j}) + 4u(\mathbf{x}_{i,j}) - 2u(\mathbf{x}_{i-1,j}) +  \\
&\hspace{17em} u(\mathbf{x}_{i+1,j-1}) - 2u(\mathbf{x}_{i,j-1}) + u(\mathbf{x}_{i-1,j-1})  \\
& = h_x^2 h_y^2 \frac{\partial^4 u}{\partial y^2 \partial x^2} (\mathbf{x}_{i,j}) +
\frac{1}{12} h_x^2 h_y^4 \frac{\partial^6 u}{\partial y^4 \partial x^2} (\mathbf{x}_{i,j}) +
 \frac{1}{12} h_x^4 h_y^2\frac{\partial^6 u}{\partial y^2 \partial x^2} (\mathbf{x}_{i,j}) + O(h_x^2 h_y^4) + O(h_x^4 h_y^2).
\end{aligned}
\label{eq:3-1-5}
\end{equation}
Combining \eqref{eq:3-1-4} with \eqref{eq:3-1-5}, we have
\[
\bar{L}_h [u(\mathbf{x}_{i,j})] = - \frac{\partial^2 u}{\partial x^2} (\mathbf{x}_{i,j}) - \frac{\partial^2 u}{\partial y^2} (\mathbf{x}_{i,j}) 
-\frac{1}{12} \left( h_x^2 \frac{\partial^2}{\partial x^2} + h_y^2 \frac{\partial^2}{\partial y^2} \right) \left( \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2}\right)  (\mathbf{x}_{i,j}) + O((h_x^2 + h_y^2)^2).
\]
It remains to determine $\bar{f}(\mathbf{x}_{i,j})$. 
We note that$
{f}(\mathbf{x}_{i,j}) = -[\Delta u](\mathbf{x}_{i,j})
$, 
and
\[
\frac{1}{12} \left(h_x^2 \frac{\partial^2 f}{\partial x^2} + h_y^2 \frac{\partial^2 f}{\partial y^2} \right) (\mathbf{x}_{i,j}) = -\frac{1}{12} \left( h_x^2 \frac{\partial^2}{\partial x^2} + h_y^2 \frac{\partial^2}{\partial y^2} \right) \left( \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2}\right)  (\mathbf{x}_{i,j}),
\]
which leads to the desired result: $\bar{R}_{i,j} = O(h_x^4+h_y^4)$ if $h_x=O(h_y)$.
\end{proof}


\newpage
\section*{Appendix: Notations for Discrete Representation}
 Let $I = [a,b]$. We define the discrete grid points as
\[
a=x_0<x_1<\cdots<x_N = b.
\]
We introduce the following sets:
\[
I_h = \{x_1,\cdots,x_{N-1}\}, \ \bar{I}_h = \{x_0,x_1,\cdots, x_N\}, \ I_h^+ = \{x_1,\cdots,x_N\}.
\]
The grid spacing is defined as
\[
h_i = x_{i}- x_{i-1}, \quad i=1,\cdots,N.
\]
Additionally, we define the averaged grid spacing:
\[
\begin{aligned}
& \bar{h}_i = \frac{1}{2} (h_i+h_{i+1}), \ i=1,\cdots,N-1,\\
& \bar{h}_0  = \frac{1}{2} h_1, \quad \bar{h}_N = \frac{1}{2} h_N.
\end{aligned}
\]
A discrete function defined on $\bar{I}_h$ is denoted as 
\[
v_h = [v_0,v_1,\cdots, v_N ]^\mathrm{T}.
\]
We define the following difference operators:
\[
\begin{aligned}
& (v_i)_{\bar{x}} := v_{i,\bar{x}} : = \frac{v_i-v_{i-1}}{h_i}, \ i =1,\cdots,N, \\
& (v_i)_x := v_{i, x} := \frac{v_{i+1} - v_i}{h_{i+1}},\ i=0,\cdots,N-1, \\
&  (v_i)_{\hat{x}} := v_{i, \hat{x}} := \frac{v_{i+1} - v_i}{\bar{h}_{i}},\ i=0,\cdots,N-1.
\end{aligned}
\]
The discrete inner products are given by
\begin{equation}
(u_h, v_h)_{I_h} = \sum_{i=1}^{N-1} u_i v_i \bar{h}_i, \
(u_h, v_h)_{\bar{I}_h} = \sum_{i=0}^{N} u_i v_i \bar{h}_i, \
(u_h, v_h)_{I^+_h} = \sum_{i=1}^{N} u_i v_i h_i.
\label{eq:d-ip}
\end{equation}
We define the discrete norms as follows:
\begin{equation}
\begin{aligned}
& \|v_h\|_c := \max_{\bar{I}_h} |v_i|,\ \|v_h\|_0 := (v_h,v_h)_{\bar{I}_h}^{1/2}, \\
& |v_h|_1 := ((v_h)_{\bar{x}}, (v_h)_{\bar{x}})_{I_h^+}^{1/2}, \ \|v_h\|_1^2 = \|v_h\|_0^2 + |v_h|_1^2.
\end{aligned}
\label{eq:d-in}
\end{equation}
The discrete integral by parts:
\begin{equation}
\sum_{i=m+1}^n v_i (w_i)_{\bar{x}} h_i = - \sum_{i=m}^{n-1} (v_i)_x w_i h_{i+1} + v_n w_n - v_m w_m,\ \text{for some} \ 0\leqslant m < n \leqslant N.
\label{eq:d-ibp}
\end{equation}
The discrete Green formula:
\begin{equation}
\sum_{i=m+1}^{n-1} \left( (u_i)_{\bar{x}} \right )_{\hat{x}} v_i \bar{h}_i = - \sum_{i=m+1}^n (u_i)_{\bar{x}} (v_i)_{\bar{x}} h_i + (u_n)_{\bar{x}} v_n - (u_m)_x v_m,\ \text{for some} \ 0\leqslant m < n \leqslant N.
\label{eq:d-gf}
\end{equation}
The discrete Cauchy-Schwarz inequality states that
\begin{equation}
|(u_h, v_h)_{\bar{I}_h}| \leqslant (u_h, u_h)_{\bar{I}_h}^{1/2} (v_h, v_h)_{\bar{I}_h}^{1/2}.
\label{eq:d-csi}
\end{equation}
If $v_0 = 0$ (or $v_N=0$ or $v_0=v_N=0$), the discrete Poincar\'e inequality holds:
\begin{equation}
\|v_h\|_c \leqslant C |v_h|_1, \quad \|v_h\|_0 \leqslant C |v_h|_1,
\label{eq:d-pi}
\end{equation}
where $C$ is a constant depending only on $a$ and $b$.


\end{document}

