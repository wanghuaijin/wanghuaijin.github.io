---
title: 0214-DeepSeek alternatives
cover: /assets/EngLearn/world2025/250214.jpg
date: 2025-02-14
article: true
star: false
timeline: false
toc: false
sidebar: false
---
Feb. 14, 2025
<!-- more -->

## Alibaba’s Qwen AI models enable low-cost DeepSeek alternatives from Stanford, Berkeley[^t1]


&nbsp; The race to produce the cheapest top-performing artificial intelligence (AI) model is heating up with a new reasoning model from US computer scientists, including 
<span class="hover-note">
renowned
<span class="hover-content">
renowned: 著名的
</span></span>
 Chinese-American “AI godmother” Li Feifei, that was trained 
<span class="hover-note">
for
<span class="hover-content">
for: 以...钱
</span></span>
 under US$50 on the back of Alibaba Group Holding’s open-source technology, following the breakthrough success of China’s DeepSeek. 

&nbsp; The S1 reasoning model was developed on top of the Chinese e-commerce giant’s Qwen2.5-32b-Instruct model by researchers from Stanford University, where Li works, and the University of Washington, according to a research paper published last week. 

&nbsp; The capabilities of Alibaba’s model are 
<span class="hover-note">
fresh
<span class="hover-content">
fresh: 最新的
</span></span>
 evidence of how China is narrowing the AI gap with leading US players, following DeepSeek’s release of low-cost, high-performance open-source models that captured global attention.

&nbsp; After being trained with answers to 1,000 carefully 
<span class="hover-note">
curated
<span class="hover-content">
curate: 组织 v.
</span></span>
 questions and the “thinking process” 
<span class="hover-note">
distilled
<span class="hover-content">
distill: 蒸馏 v.
</span></span>
 from Google’s Gemini Thinking Experimental model, the S1 model outperformed OpenAI’s o1-preview on maths and programming skills, according to the paper.


[^t1]: 阿里巴巴的通义千问人工智能模型支持来自斯坦福大学伯克利分校的低成本DeepSeek替代品